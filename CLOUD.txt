BASICS
1.Every network adapter in a network must have a IP address, it is alloted by wifi router
2.cd ~ or cd -> come back to home directory, cp -r directory directory
3.cp -r devdir bacupdir/ --> command option argument => for options --> command --help
4.mv --> move and rename the file, ls -l --> long listing of files, file starting with - in the beginning is a regular file => it can be binary or text file etc. ls -lt --> arranges according to the timestamp. ls -ltr --> reverses.
5.d -> directory, /dev/ conatins device files, c -> character file, b -> block file, l -> link file i.e it is shortcut to original file
6.ln -s destination source --> create a soft link, to remove a link unlink linkname, mkdir -p --> it will make the entire file structure as mentioned

FILTERING AND REDIRECTIONING
1.grep -iR word < file  ==> it will search the word not only inside files but directory also,grep -v word ==> will show everything except the mentioned word
2.head -20 filename --> reads first 20 lines
3.tail -f filename --> it will show the dynamic contents of the file, useful while reading log files
4. awk -F'delimitor' 'print $1' /etc/passwd
5.for search and replace --> open vim(if you want to change a single file) --> %s/wordToBeReplaced/newWord/g(for doing globally). For changing in multiple files use sed -i's/wordToBeReplaced/newWord/g' inWhichFile. Without using i, it will just print after replacing and not change actually.
6.uptime > /tmp/sysinfo.txt, if sysinfo.txt is not there then it will create it, if it already exists it will overwrite the contents in it.BUT if we don't want to overwrite then use >>.
7. free -m --> memory utilisation, df -h --> harddisk partition utilisation. echo "content  ". if we don't want to see the output then move the contents to /dev/null.freeee -m 2(it is for error as freeee -m will throw an error and we want to redirect it without seeing the error message)>> /tmp/error.log ==> free -m 1(it is by default)>> /tmp/error.log. Can use & for handling both std err and std o/p.
8. wc -l --> counts the number of lines, find /etc -name host*(i.e find all file in the etc directory having host in it) --> for finding file.(don't search directly in the root directory as it will make your system slow as it is a real time search.). Before running locate command do updatedb as it is not a real time search.
9. id user --> gives information about that user, if I want to add all users to the group then use -aG for supplementary or secondary group, or use -ag for primary group. usermod -aG groupName (username which you want to add). To set or reset password use passwd username. Being root user you don't need password --> su - username --> to change to that user from root. last --> to see users who logged into the system.
10. To delete the user if we use userdel username then its home directory and mailing spool will still be there, to delete it also we will do userdel -r username

FILE PERMISSIONS:-
1.to find permissions of a directory use ls -ld, to change ownership recursively(i.e for subdirectories inside it.) use chown -R username:groupname <filepath>.
2.we will not make changes directly in sudoers file, we will make changes in /etc/sudoers.d file.

SOFTWARE MANAGEMENT:-
1.rpm -ivh ==> i -> install, v -> verbose, h -> in human readable format.rpm -qa --> will list all the rpms.cat /etc/systemd/system/multi-user.target.wants/httpd.service, this file automatically gets created when we install httpd through yum.

PROCESSES:-
1.top--> shows all the dynamic processes based on their consumption of cpu and ram.Similar to task manager in windows.ps aux --> similar to top but top shows the dynmaic processes and ps aux will show the processes and quit.PID 1 is the first process, in older linux systems it is init but in newer ones it is systemd. In ubuntu it is systemd only, this process will start so many other processes and will handle many child processes also.
2.ps aux --> sort according to PID number, ps -ef --> will also show PPID(parent process ID), one process starts other processes, this is called as forking.
3. kill PID --> it will first kill all the child processes then it will kill itself. Sometimes the processes become admin and it becomes difficult to kill, so we need to do it forcefully by typing kill -9 PID --> this will kill the parent process only and all the child processes will become orphan processes(they are adopted by PPID 1),(in new versions the orphan process are cleared automatically).
4.To clear them use ps -ef | grep httpd | grep -v 'grep' | awk {'print $2'} | xargs kill -9
5.To clear zombie processes reboot your machine. Zombie processes are the processes which are dead but their entry is still on the table. They don't use any resources but can become a problem.

ARCHIEVING:-
1.we do archieving of log files so that we can move them to other places and save disc space.
2.tar -czvf jenkins_timestamp.tar.gz path_you_want_to_archieve. c --> create, z --> compressing the file, v --> verbose, f --> file, tar is for tar ball, gz --> gun zip.
3.tar -xzvf tar_file--> x is for extraxt. If we want to extract in other directory then we need to use tar -xzvf tar_file -C <file directory where you want to extract it.> 
4. zip -r(if you are acrchieving or compressing a directory.) and unzip <tarball> --> to unzip it.

PURPOSE- networking through vagrant, how to alot ip addresses to vms as per our need and change some port numbers
provisioning==> when VM is coming up we want to run some linux commands, how to change RAM CPU and disk utilisation.
creating multiple vms through single vagrant file.


vagrant global-status ==>to show all the status of vms that we have
vagrant global-status --prune ==> to remove the prvious information
vagrant status ==> to get the status of VM runnig in the current directory
ls -a ==> shows all the files including the hidden files.
when you'll do vagrant up for the first time then a hidden file .vagrant will be created which will be readed whenever we write like vagrant halt,destroy, remove then it will come and read the .vagrant file for the information about VM running.
~/.vagrant.d is a global vagrant file the is hidden in the home directory & it will contain vagrant boxes you download and login keys and few other things.
==>the vagrant file is written in ruby, # commments out the statement, and in vagrant file most of them are commented out.

==>while we created VM manually we have created a bridge interface, if we want to the same with vagrant then we are going to see a setting config.vm.network "public_network". All the settings must start with config.if we uncomment the previous one then it means give me one more adapter that is co-nnected to bridge netwrok and that is going to give me IP address from my Wi-Fi router.This is going to fetch IP from wireless router, so it is going to be dynamic. 

==> config.vm.network "private_network", ip: "192.168.33.10"
if we uncomment this then we will get a static IP address, so third octet may be something else like 25.12 .

==>If we want to change RAM size then we need to uncomment
   config.vm.provider "virtualbox" do |vb|  and then end.

==>ifconfig is going to show all the network interface and their IP addresses, we can tell the nat adapter by seeing the IP address as it is same for every VM.

==> after vagrant ssh the vagrant file in the directory is synced with the /vagrant file in the VM .

==> if our VM unexpectedly crashes or aborts then our data may be gone so to have data we can save it in /vagrant file of VM and it will automatically saved in the directoty of our computer

==> to run the bash script file give the absolute path

==> the default sync directory is /vagrant and the to change that and keep it as per our need we need to edit vagrant file, we need to uncomment   config.vm.synced_folder "../data", "/vagrant_data" and write the wanted path in the place of ../data by D:\\myshellscripts==> we need to apply one more \ because we are converting from linux to windows.

==>provisioning is executing of commands and bash scripts when the VM comes up.In other technologies it is also called as bootstraping, so when OS is booting for the fisrt time run the scripts/code.
==>if VM is up then provisioning will not work.
==>if VM is not existing then after changing in vagrant file , vagrant up command will work, BUT if it already exists then use vagrant reload --provision, the provisioning wil not run automatically by themselves they need to be ran by writing vagrant reload --provision bcoz if they would run automatically then they would give weird errors.

######SERVER MANAGEMENT######

1. Website on centos-7 httpd service and HTML templates.
2. hosting wordpress on ubuntu 18 using LAMP stack linux,apache2,mysql,php.
3.then automation using vagrant provisioning.

ip addr show ==> same as ifconfig
systemctl start httpd
systemctl enable httpd
cd /var/www/html==>here we keep our codes that we want to host.
in any case we make configuration changes to the server then service needs to be restarted using systemctl restart httpd , we are deploying our website so we need to bounce our service so we use systemctl restart httpd.

###WEBSITE AUTOMATION###

we'll put all the codes required for manual setup of the wavecafe website in th vagrant provisioning section and when we do that it is known as IAAC(infrastructure as a code). Cloud formation, terraform are IAAC for the cloud computing environment like we are using vagrant for our local VMs.

IMP:-Infrastructure as code (IaC) is the process of managing and provisioning infrastructure (networks, virtual machines, load balancers, and connection topology) through CODE/Config Files.

E:g

Vagrant for local
Terraform for Cloud
Ansible for Servers

Cloudformation for AWS

etc

if we are doing vagrant up again and again then the zip file would already exist and ask questions to override it, to overcome this problem use -o in unzip command like unzip -o 2121_wave_cafe.zip

we can write the mysql commands through the shell also by writing mysql -u root -e 'write the command between these two'
 
we are provisioning infrastructure with code that is called IAAC, with this we can avoid human errors, save alot of time, and best part is we can version control our infrastructure

###MULTI VM VAGRANT FILE###
In a multiVM environment are goint to talk to each other then we should give static IP to them.Mariadb is the mySQL package in centos7
To bring up VM using the vagrant ssh command use name of VM you want to bring up, abd for halt if we'll not use the name of VM then both will stop automatically. It is same for vagrant destroy and vagarant reload

Provisioning is the process of configuring and deploying an information technology (IT) system resource either locally or in the cloud. In enterprise computing, the term is often associated with virtual machines (VMs) and cloud resource instances.

PYTHON DS, JSON, YAML:-
=>data exchanges in devops uses mostlyh JSON and YAML, as a devops engineer its essential to understand, read and write this data format for exchange between diffferent applications and languages.
=>variables are temporary storage of data in RAM. So they live in the programme
=>variable="value"
->echo $varibale --> value
->echo variable --> variable
->echo 'i am $variable' --> i am $variable
->echo "i am $variable" --> i am value


###VPROFILE PROJECT SETUP###
=>Multi Ties Web Appplication stack
=>setup on laptop/dektop
=>baseline for upcoming events
helps you setup any project locally and we can setup the entire setup locally and we can do our R&D.

PROBLEM:-
=>the problem is we are not comfortable in making changes in real servers bcoz
=>local setup is complex
=>time consuming
=>not repeatable

SOLUTION:-
==>we will have the local setup but it will be automated, repeatable and the code[IAAC] will be used, since we have have infrastructure as a code we can repeat it as many times we want.

TOOLS:-
=>hypervisor - oracle VM virtualbox
=>automation - vagrant
=>CLI - git bash
=>IDE(any)

we will make a web app in which user will enter the ip address (the ip address will be of the load balencer) and we are going to us NGINX to create load balancing experience.NGINX is open source software for web serving, reverse proxying, caching, load balancing, media streaming, and more.

=> we'll configure it in such a way that as soon as the web request comes it is going to route the request to  Aache tomcat server(it is a JAVA web application service). If our application needs external storage we can use NFS(The Network File System (NFS) is a mechanism for storing files on a network. It is a distributed file system that allows users to access files and directories located on remote computers and treat those files and directories as if they were local.)

=> In our project RabbitMQ(RabbitMQ is a messaging broker, or queying agent - an intermediary for messaging) is dummy, we added it just to make the system more complex

=>the web application is ran through tomcat, to get the user information stored in the mysql database but before going to mysql database the request will go to memcached(Memcached (pronounced variously mem-cash-dee or mem-cashed) is a general-purpose distributed memory-caching system. It is often used to speed up dynamic database-driven websites by caching data and objects in RAM to reduce the number of times an external data source (such as a database or API) must be read.) for the first time the user infi will go from mysql server to tomcat but next time it will come from the cached info in memcached.(just as browser caching we have datbase caching.)

=> we need to understand the flow of the stack. As a devops we are more focussed on implementation rather than functionality.

//AUTOMATION SETUP//
vagrant, vm virtualbox, bash scripts.

//FLOW OF EXECUTION//
clone source code, bring up VMS, validate that they are working and interacting with each other, setting up services
1.MYSQL
2.memcached(database caching)
3.rabbitMQ(message broker or queying agent)
4.tomcat(java web application service)
5.nginx(load balancer)
6.deploy webapp  
verify using web browser

=>vagrant plugin install vagrant-hostmanager, it maps all the ips with hostnames
==>plugins are used for extra feature, the above one ensures that the hostname and ip address are being stored in /etc/hosts
=>mariadb-server is the package name and mariadb is the service name

=>mysql_secure_installation => it is script which will ask a series of questions just  check the mysql services is secure

==> every sql command ends with a semicolon
==> wheneve you are going to set up any service or anything then you must do the update -y command.

==> memcached -p 11211 -U 11111 -u memcache -d, 11211 => TCP(transmission control protocol) and 11111 => UDP(user datagram protocol), we can validate if the memcached is running on the right port or not by using ss -tunlp | grep 11211
==>network check --> ping app01 -c 4(number of ping packets that will be transmitted)

==>we always start setting up from the backend like database, then queying/caching, application service then web service.

=>Tomcat is an application server to host Java Web Application like vprofile.

Nginx is a frontent server, web server and can be used as a Load balancer.

Mysql is a SQL Database server, similar are Mariadb, MSSql etc
-->grant all privileges on accounts.* TO 'admin'@'%' identified by 'admin123';
==>Above % means admin user of this database can connect to this database from remote machine.
-->sed -i 's/127.0.0.1/0.0.0.0/g' /etc/sysconfig/memcached --> some services only work in local machine, to connect with that service remotely from any other machine we need to do this config change.
0.0.0.0 --> means listen from all the ipv4 addresses
RabbitMQ is the most widely deployed open source message broker.

Memcached is an in-memory key-value store for small chunks of arbitrary data (strings, objects) from results of database calls.

==>application.properties is used by tomcat server to find information of all the backend services
mysql, memcache, RabbitMQ, Elasticsearch

In source code its located in vprofile-project/src/main/resources/application.properties.

==> jre --> java runtime environment --> it is to run java based application
==> jdk --> java devlopment kit --> used to devlop java based applications.

-->Whenever you make any change in the file /etc/systend/system --> execute this command --> systemctl daemon-reload

###COMPUTER NETWORKING###
=>components, OSI model, Classification, Devices, Home Network, IP addresses, Protocols, DNS & DHCP, Network commands.

==>What is COMPUTER NETWORKING?
the communication between two or more network interfaces.

==>COMPONENTS OF CN:-
Two or more computers/devices, cables as links between the computers, network interfacing card(NIC) on each device, computer, 
switches- to connect multiple network interfaces together, router - to connect multiple network together, software called operating system(OS)

==>OSI MODEL:-(OpenSystems Interconnection)
1.people aroungd the world uses computer network to communicate with each other.
2.for the worldwide data communication, systems must be developed whch are compatible to communicate with each other.
3.there should be standard communcation methods and devices.
4.ISO(international organisation of standardiztion) has developed this standard.

communication system is devloped as if it is some kind of language which is to be understood by everyone.

=>This communication model is called as Open System Interconnection(OSI)
=>OSI-ISO model is a seven layer archietecture devloped in 1984.
 
=>The basic elements of a layered model are:-
1.services
2.protocols
3.and interfaces.
#A service is a set of actions that a layer offers to another (higher) layer
#A protocol is a set of rules that a layer uses to exchange information.
#Interface means communication between the layers.

#OSI MODEL:-
physical - bits
data link - frames
network - packets
transport - segmemts
session - data
presentation - data
application - data  

In tcp/ip protocol the application, presentation and session layer are considered to be a single layer.
 
###CLASSIFICATION OF NETWORKS BASED ON GEOGRAPHY###
=>LAN - local area network. ex -room computers
=>WAN - wide area network. ex -internet
=>MAN - metropolitan area network
=>CAN - campus area network
=>PAN - personal area network
###SWITCHES AND ROUTERS###
switches facilitates the sharing of resources by connecting together all the devices, including computers, printers, and servers, in a small business network.switch connects multiple computers together.
  
##ROUTERS
a router connects multiple networks together. A router recieves and sends data on computer networks. Routers are sometimes confused with network hubs, modems, or network switches. However, routers can combine multiple networks together. It connects LAN with WAN.
###HOME NETWORK###
 
###CORPORATE NETWORK DIAGRAM###
 
###IPv4 ADDRESS###
 
32 BIT binary number, range of IPv4 0.0.0.0 to 255.255.255.255
00000000.00000000.00000000.00000000 => lowest possible IPv4 address
11111111.11111111.11111111.11111111 => highest possible IPv4 address
==> Public IP => with the ISP or cloud service provider, ex- 54.86.23.90, this is our identity in network, it is mostly dynamic. 
==>Private IP is for people like us to create our own network.ex - 192.168.1.10, it is mostly static.Its ranges are as follows:-(IMPORTANT)
class A:- 10.0.0.0 -> 10.255.255.255
class B:- 172.16.0.0 -> 172.31.255.255
class C:- 192.168.0.0 -> 192.168.255.255
###PROTOCOLS###
In the networking and communications area, a protocol is the formal specification that defines the procedures that must be followed while transmitting and recieving data. Protocols define the format, timing, sequence and error checking use on the network.
  
we need to know the port numbers as they will be helpful while setting the firewalls, or security grooups. Like computer have an IP address a service running inside the computer will have a port number
###LOOKING OSI 7 LAYER MODEL WITH TCP/IP PROTOCOLS###
 
lets us say tomcat on one machine wants to communicate with mysql on ther machine then
tomcat     ==>              Source 192.168.1.2:8080 Dest 192.168.1.2:3306   ==>                  MySQL                     
192.168.1.2:8080                                                                                                      192.168.1.3:3306     

###NETWORKS COMMANDS###
==>when we get inside the the  multivm file using the vagrant up, and then do ifconfig then it shows the connected ip addresses,
1. connected to nat network
2.connected to IP(the static IP which we provided) address.
3.lastly it shows the loopback address, this is used when computer refers to itself, you can say that it is a local network interface.
==> ping releases the network connectivity from the machine to the IP address on which ping is applied, it shows network connectivity is there or not and the packets are not lost.
==> if i don't want to use a IP address instead i want a name then i will need a DNS server or i can make an entry to the /etc/hosts in root directory. If i want to add the db01 there then i need to write 192.168.40.12 db01
==>if you want to trace the complete path that the computer has taken to reach the target machine then you can use trace root(tracert www.google.in(for example)) . This command is used to see whether there is latency between a computer to some target machine. Then we can see that the latency is where and findout the problem.
==>netstat -antp => tells about all the open TCP ports. if we are root user then only we will be able to see the PID(process ID) 
==> ps -ef | grep apache2 => to search for apache 2 from the processes
==> ss -tunlp => to see open ports on the machine with name and PID
==> nmap => scannig the port of a target, for whether they are open or not. if we are trying to connect two machines, and they are not connecting then we will use nmap to scan the ports to see whether it is open or not.
==>dig www.google.com( for example) => it will show us the DNS lookup, like it will show us that name can be resolved to IP address or any other record. nslookup www.google.com (for example) is also same as the dig command but it is old.
==>route -n => this command is going to show you the gateways
==> arp => used to add or view content of kernels arp table
==>mtr => same as traceroute but it is live (dynamic)
==> we can use telnet command also to see whether a particular port is open or not in the target machine.ex- telnet 192.168.40.12 3306 i.e trying to connect web01 and db01 on port 3306.
###CONTAINERS###
DOCKER-Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure so you can deliver software quickly. With Docker, you can manage your infrastructure in the same ways you manage your applications.
DCKER HOST- computer on which all the things are going to happen.
DOCKER DAEMON- it is the docker service that we are going to install, so we'll have a VM and we'll install the docker engine on that and run the containers., we'll run them from image and the image we'll be get from registry.
 
client can be on the same machine or different machine or different machine, we'll create a VM , we'll install the docker engine and that will have the docker client also and with
docker build - we can build our own images
docker pull - to pull the images from registry.
docker run - run the container from the image.
docker containers are created from docker images.
==> docker run hello-world => this will test whether the docker installation is fine or not.
==>docker images => available images on your system., docker ps => will show running containers , docker ps -a => will show you all the containers.
==>docker run --name web01 -d -p 9080:80 nginx --> -d ==> to run the processes in background. -p to assign hostport to container port.
==>Container will be running in internal network, so it can't be accessed from outside, in order to access it from outside we use port mapping.
==>To access the container locally we need its ip, so use docker inspect containerName/ContainerID. Now type curl http://IPaddress:containerPort. for example(curl http://172.17.0.2:80)
==>If we want to run multiple containers together then there is concept of docker compose, it will read file dockercompose.yaml file.
==> docker compose down to stop and remove the container, docker system prune -a --> will remove all the containers and images if they are not used.

BASH SCRIPTING:-
In Linux, process automation relies heavily on shell scripting. This involves creating a file containing a series of commands that can be executed together.
==>Bash script is a text file that may ave an extension .sh , it will start with a shebang character #! --> it tells the path of the interpreter i.e open the interpreter and execute the commands written in it.
==>to run a bash script, do ./scriptName , to comment inside bashscript use #comment. we need to change the permissions of the bash script file if it doesnot execute --> chmod +x bashfileName.
#Variable Declaration
PACKAGE="httpd wget unzip"
SVC="httpd"
URL="https://www.tooplate.com/zip-templates/2098_health.zip"
ART_NAME="2098_health"
TEMPDIR="/tmp/webfiles"
==>to use variable, $variableName.

command line argument:-
==>value of variable 0 is by default the name of the script. i.e. echo $0 prints the name of the bashscript file.
==>If we try to echo a variable that is not defined then it will be shown empty.
==>$1-$9, the first 9 arguments to the bash script.
==>wget $1 > /dev/null  -->we are asking for the URL
unzip $2.zip > /dev/null --> then we are asking for the artifact name
sudo cp -r $2/* /var/www/html/
i.e after writing this command in the bashscript, our code becomes reusable.

==> echo $? --> prints the exit code --> if it is 0 the previous command was a success, it is non-zero then the previous commmand failed.
==> echo $RANDOM --> give random number in the range 0 â€“ 32767

QUOTES --> single and double both, inside double quotes the meaning of special character is there but inside single quote the meaning of special character is not there.
[root@scriptbox ~]# echo 'I have $SKILL skills'
I have $SKILL skills --> for single quotes

[root@scriptbox ~]# echo "I have $SKILL skills"
I have Devops skills --> for double quotes

[root@scriptbox ~]# echo "due to $VIRUS we lost $9 million"
due to covid19 we lost  million
[root@scriptbox ~]# echo "due to $VIRUS we lost \$9 million"
due to covid19 we lost $9 million --> after using backslash in front of any special character, it special meaning is ignored.

==>COMMAND SUBSTITUTION --> it stores the output of the command in a variable.
[root@scriptbox ~]# UP=`uptime` --> to store the command o/p use `` --> backticks
[root@scriptbox ~]# echo $UP

[root@scriptbox ~]# CURRENT_USER=$(who) --> one more way
[root@scriptbox ~]# echo $CURRENT_USER
vagrant pts/0 2023-12-28 07:11 (10.0.2.2)

so --> either `` OR $(command)

EXAMPLE:-
[root@scriptbox ~]# FREE_RAM=`free -m | grep Mem | awk '{print $4}'`
[root@scriptbox ~]# echo "free RAM is $FREE_RAM mb."
free RAM is 767 mb.

EXPORTING VARIABLES --> if you want to make variables permanent for a user or for every user in the system, then we have to export the variable.
The variable exists in the parent shell, but not in the child shell, so we can export variableName, so the varible is available for all the child shell from this parent shell.
==> Exporting the variable makes the variable global for all the child shells. 
--> BUTT if i logout from the current shell, and login again the variable is lost.

==> In every user's home directory there is a hidden file .bashrc, if we place our export and variable name in this file, then it will become permanent for the root user.
-->when any user login the bashrc file is sourced --> source .bashrc --> i.e in order to make changes visible logout and login again.
-->if we want to make the variable permanent for every user then update the /etc/profile 

-->MORAL --> if you want to make variable permanent for a user the update the .bashrc file
         --> if you want to make variable permanent for everyone then update the /etc/profile.

USER INPUT ==> read -p 'Username: ' USR --> -p is for prompt
               read -sp 'Password: ' pass --> -sp is for suppressing the input

we don't want script to be interactive in devops since it is error prone.
--> whenever a process is running a pid file must be created. cat /var/run/httpd/httpd.pid, if we will stop the service the file will cease to exist.

CRON JOBS --> if we want to run a process again and again a particular schedule then we use cron jobs, they are scheduled tasks
crontab -e is going to edit --> i.e it will open a vim editor ==>
# minute hours dayOfMonth month dayOfWeek COMMAND
# 30 20 * * 1-5 COMMAND
* * * * * /opt/scripts/11_monit.sh &>> /var/log/monit_httpd.log
* --> for every interval
==> we have created an intelligent script that will be running on a fixed schedule.


REMOTE COMMAND EXECUTION --> how can we execute command from scriptbox to web01 and web02 and web03.
-->we are going to add names to IP mapping in the scriptbox. so scriptbox can refe to all the machines with their names and not IP addresses.

-->Add the ip addresses to the /etc/hosts --> 192.168.10.13 web01
                                              192.168.10.14 web02
                                              192.168.10.15 web03

==>ssh vagrabt@web01 trying to SSH into a virtual machine named "web01" using the Vagrant user
==>whenever i was trying to log into web01, web02, it was asking me password, but for web03 --> Permission denied (publickey) --> so ubuntu doesnot allow password login.
-->vagrant ssh web03 is keybased login --> if any linux machine you are trying to login with password and if it throws you that public access denies then, open the /etc/ssh/sshd_config --> and find the line password authentication, if it is no then do it yes.
-->then restart the ssh service --> in ubuntu the name of ssh service is ssh only.
-->add user devops in all the VMs --> web01 web02 web03
-->now from scriptbox we can remote execute commands in these VMs --> ssh devops@web01 uptime --> shows uptime of web01 and then come back to same command ineterface.

SSH key Exchange --> we can do the above but the problem is everytime it asks for password.
BUT there is one more way to login i.e key based. key based login are considered more safer
--> To generate the key --> ssh-keygen
[root@scriptbox ~]# ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /root/.ssh/id_rsa. --> this works as a key
Your public key has been saved in /root/.ssh/id_rsa.pub. --> this works as a lock
so we will put the lock(public key) in web01 web02 web03 by --> ssh-copy-id user@hostname 
==>CONCLUSION --> now if we will do --> ssh user@hostname command --> it will not ask for password

-->/root/.ssh/id_rsa --> private key will be here --> it is longer than the public key.
-->/root/.ssh/id_rsa.pub --> public key will be here.
-->when lock matches with the key(since both are generated in pairs) then we get authenticated.
--> now when we will do ssh user@hostname then it is actually written --> ssh -i /root/.ssh/id_rsa user@hostname

==>to push file from one VM to other VM do --> scp sourceFile destination:<file path> --> scp testfile.txt devops@web01:/tmp/
-->scp doesnot asks any password, if there is any password then the key is not exchanged.
--> ############################################################for deployment of multiple VMs.
#!/bin/bash

USR='devops'

for host in $(cat remhosts)
do
  echo
  echo "############################################"
  echo "connecting to $host"
  echo "pushing script to $host"
  scp multios_websetup.sh $USR@$host:/tmp/
  echo "executing script on $host"
  ssh $USR@$host sudo /tmp/multios_websetup.sh
  ssh $USR@$host sudo rm -rf /tmp/multios_websetup.sh
  echo "############################################"
  echo
done
~
##################################################################

AWS ==> Cloud Computing --> Cloud computing is the on-demand delivery of IT resources over the Internet with pay-as-you-go pricing. Instead of buying, owning,
and maintaining physical data centers and servers, you can access technology services, such as computing power, storage, and databases, on an as-needed basis 
from a cloud provider like Amazon Web Services (AWS).
