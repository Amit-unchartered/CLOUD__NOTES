BASICS
1.Every network adapter in a network must have a IP address, it is alloted by wifi router
2.cd ~ or cd -> come back to home directory, cp -r directory directory
3.cp -r devdir bacupdir/ --> command option argument => for options --> command --help
4.mv --> move and rename the file, ls -l --> long listing of files, file starting with - in the beginning is a regular file => it can be binary or text file etc. ls -lt --> arranges according to the timestamp. ls -ltr --> reverses.
5.d -> directory, /dev/ conatins device files, c -> character file, b -> block file, l -> link file i.e it is shortcut to original file
6.ln -s destination source --> create a soft link, to remove a link unlink linkname, mkdir -p --> it will make the entire file structure as mentioned

FILTERING AND REDIRECTIONING
1.grep -iR word < file  ==> it will search the word not only inside files but directory also,grep -v word ==> will show everything except the mentioned word
2.head -20 filename --> reads first 20 lines
3.tail -f filename --> it will show the dynamic contents of the file, useful while reading log files
4. awk -F'delimitor' 'print $1' /etc/passwd
5.for search and replace --> open vim(if you want to change a single file) --> %s/wordToBeReplaced/newWord/g(for doing globally). For changing in multiple files use sed -i's/wordToBeReplaced/newWord/g' inWhichFile. Without using i, it will just print after replacing and not change actually.
6.uptime > /tmp/sysinfo.txt, if sysinfo.txt is not there then it will create it, if it already exists it will overwrite the contents in it.BUT if we don't want to overwrite then use >>.
7. free -m --> memory utilisation, df -h --> harddisk partition utilisation. echo "content  ". if we don't want to see the output then move the contents to /dev/null.freeee -m 2(it is for error as freeee -m will throw an error and we want to redirect it without seeing the error message)>> /tmp/error.log ==> free -m 1(it is by default)>> /tmp/error.log. Can use & for handling both std err and std o/p.
8. wc -l --> counts the number of lines, find /etc -name host*(i.e find all file in the etc directory having host in it) --> for finding file.(don't search directly in the root directory as it will make your system slow as it is a real time search.). Before running locate command do updatedb as it is not a real time search.
9. id user --> gives information about that user, if I want to add all users to the group then use -aG for supplementary or secondary group, or use -ag for primary group. usermod -aG groupName (username which you want to add). To set or reset password use passwd username. Being root user you don't need password --> su - username --> to change to that user from root. last --> to see users who logged into the system.
10. To delete the user if we use userdel username then its home directory and mailing spool will still be there, to delete it also we will do userdel -r username

FILE PERMISSIONS:-
1.to find permissions of a directory use ls -ld, to change ownership recursively(i.e for subdirectories inside it.) use chown -R username:groupname <filepath>.
2.we will not make changes directly in sudoers file, we will make changes in /etc/sudoers.d file.

SOFTWARE MANAGEMENT:-
1.rpm -ivh ==> i -> install, v -> verbose, h -> in human readable format.rpm -qa --> will list all the rpms.cat /etc/systemd/system/multi-user.target.wants/httpd.service, this file automatically gets created when we install httpd through yum.

PROCESSES:-
1.top--> shows all the dynamic processes based on their consumption of cpu and ram.Similar to task manager in windows.ps aux --> similar to top but top shows the dynmaic processes and ps aux will show the processes and quit.PID 1 is the first process, in older linux systems it is init but in newer ones it is systemd. In ubuntu it is systemd only, this process will start so many other processes and will handle many child processes also.
2.ps aux --> sort according to PID number, ps -ef --> will also show PPID(parent process ID), one process starts other processes, this is called as forking.
3. kill PID --> it will first kill all the child processes then it will kill itself. Sometimes the processes become admin and it becomes difficult to kill, so we need to do it forcefully by typing kill -9 PID --> this will kill the parent process only and all the child processes will become orphan processes(they are adopted by PPID 1),(in new versions the orphan process are cleared automatically).
4.To clear them use ps -ef | grep httpd | grep -v 'grep' | awk {'print $2'} | xargs kill -9
5.To clear zombie processes reboot your machine. Zombie processes are the processes which are dead but their entry is still on the table. They don't use any resources but can become a problem.

ARCHIEVING:-
1.we do archieving of log files so that we can move them to other places and save disc space.
2.tar -czvf jenkins_timestamp.tar.gz path_you_want_to_archieve. c --> create, z --> compressing the file, v --> verbose, f --> file, tar is for tar ball, gz --> gun zip.
3.tar -xzvf tar_file--> x is for extraxt. If we want to extract in other directory then we need to use tar -xzvf tar_file -C <file directory where you want to extract it.> 
4. zip -r(if you are acrchieving or compressing a directory.) and unzip <tarball> --> to unzip it.

PURPOSE- networking through vagrant, how to alot ip addresses to vms as per our need and change some port numbers
provisioning==> when VM is coming up we want to run some linux commands, how to change RAM CPU and disk utilisation.
creating multiple vms through single vagrant file.


vagrant global-status ==>to show all the status of vms that we have
vagrant global-status --prune ==> to remove the prvious information
vagrant status ==> to get the status of VM runnig in the current directory
ls -a ==> shows all the files including the hidden files.
when you'll do vagrant up for the first time then a hidden file .vagrant will be created which will be readed whenever we write like vagrant halt,destroy, remove then it will come and read the .vagrant file for the information about VM running.
~/.vagrant.d is a global vagrant file the is hidden in the home directory & it will contain vagrant boxes you download and login keys and few other things.
==>the vagrant file is written in ruby, # commments out the statement, and in vagrant file most of them are commented out.

==>while we created VM manually we have created a bridge interface, if we want to the same with vagrant then we are going to see a setting config.vm.network "public_network". All the settings must start with config.if we uncomment the previous one then it means give me one more adapter that is co-nnected to bridge netwrok and that is going to give me IP address from my Wi-Fi router.This is going to fetch IP from wireless router, so it is going to be dynamic. 

==> config.vm.network "private_network", ip: "192.168.33.10"
if we uncomment this then we will get a static IP address, so third octet may be something else like 25.12 .

==>If we want to change RAM size then we need to uncomment
   config.vm.provider "virtualbox" do |vb|  and then end.

==>ifconfig is going to show all the network interface and their IP addresses, we can tell the nat adapter by seeing the IP address as it is same for every VM.

==> after vagrant ssh the vagrant file in the directory is synced with the /vagrant file in the VM .

==> if our VM unexpectedly crashes or aborts then our data may be gone so to have data we can save it in /vagrant file of VM and it will automatically saved in the directoty of our computer

==> to run the bash script file give the absolute path

==> the default sync directory is /vagrant and the to change that and keep it as per our need we need to edit vagrant file, we need to uncomment   config.vm.synced_folder "../data", "/vagrant_data" and write the wanted path in the place of ../data by D:\\myshellscripts==> we need to apply one more \ because we are converting from linux to windows.

==>provisioning is executing of commands and bash scripts when the VM comes up.In other technologies it is also called as bootstraping, so when OS is booting for the fisrt time run the scripts/code.
==>if VM is up then provisioning will not work.
==>if VM is not existing then after changing in vagrant file , vagrant up command will work, BUT if it already exists then use vagrant reload --provision, the provisioning wil not run automatically by themselves they need to be ran by writing vagrant reload --provision bcoz if they would run automatically then they would give weird errors.

######SERVER MANAGEMENT######

1. Website on centos-7 httpd service and HTML templates.
2. hosting wordpress on ubuntu 18 using LAMP stack linux,apache2,mysql,php.
3.then automation using vagrant provisioning.

ip addr show ==> same as ifconfig
systemctl start httpd
systemctl enable httpd
cd /var/www/html==>here we keep our codes that we want to host.
in any case we make configuration changes to the server then service needs to be restarted using systemctl restart httpd , we are deploying our website so we need to bounce our service so we use systemctl restart httpd.

###WEBSITE AUTOMATION###

we'll put all the codes required for manual setup of the wavecafe website in th vagrant provisioning section and when we do that it is known as IAAC(infrastructure as a code). Cloud formation, terraform are IAAC for the cloud computing environment like we are using vagrant for our local VMs.

IMP:-Infrastructure as code (IaC) is the process of managing and provisioning infrastructure (networks, virtual machines, load balancers, and connection topology) through CODE/Config Files.

E:g

Vagrant for local
Terraform for Cloud
Ansible for Servers

Cloudformation for AWS

etc

if we are doing vagrant up again and again then the zip file would already exist and ask questions to override it, to overcome this problem use -o in unzip command like unzip -o 2121_wave_cafe.zip

we can write the mysql commands through the shell also by writing mysql -u root -e 'write the command between these two'
 
we are provisioning infrastructure with code that is called IAAC, with this we can avoid human errors, save alot of time, and best part is we can version control our infrastructure

###MULTI VM VAGRANT FILE###
In a multiVM environment are goint to talk to each other then we should give static IP to them.Mariadb is the mySQL package in centos7
To bring up VM using the vagrant ssh command use name of VM you want to bring up, abd for halt if we'll not use the name of VM then both will stop automatically. It is same for vagrant destroy and vagarant reload

Provisioning is the process of configuring and deploying an information technology (IT) system resource either locally or in the cloud. In enterprise computing, the term is often associated with virtual machines (VMs) and cloud resource instances.

PYTHON DS, JSON, YAML:-
=>data exchanges in devops uses mostlyh JSON and YAML, as a devops engineer its essential to understand, read and write this data format for exchange between diffferent applications and languages.
=>variables are temporary storage of data in RAM. So they live in the programme
=>variable="value"
->echo $varibale --> value
->echo variable --> variable
->echo 'i am $variable' --> i am $variable
->echo "i am $variable" --> i am value


###VPROFILE PROJECT SETUP###
=>Multi Ties Web Appplication stack
=>setup on laptop/dektop
=>baseline for upcoming events
helps you setup any project locally and we can setup the entire setup locally and we can do our R&D.

PROBLEM:-
=>the problem is we are not comfortable in making changes in real servers bcoz
=>local setup is complex
=>time consuming
=>not repeatable

SOLUTION:-
==>we will have the local setup but it will be automated, repeatable and the code[IAAC] will be used, since we have have infrastructure as a code we can repeat it as many times we want.

TOOLS:-
=>hypervisor - oracle VM virtualbox
=>automation - vagrant
=>CLI - git bash
=>IDE(any)

we will make a web app in which user will enter the ip address (the ip address will be of the load balencer) and we are going to us NGINX to create load balancing experience.NGINX is open source software for web serving, reverse proxying, caching, load balancing, media streaming, and more.

=> we'll configure it in such a way that as soon as the web request comes it is going to route the request to  Aache tomcat server(it is a JAVA web application service). If our application needs external storage we can use NFS(The Network File System (NFS) is a mechanism for storing files on a network. It is a distributed file system that allows users to access files and directories located on remote computers and treat those files and directories as if they were local.)

=> In our project RabbitMQ(RabbitMQ is a messaging broker, or queying agent - an intermediary for messaging) is dummy, we added it just to make the system more complex

=>the web application is ran through tomcat, to get the user information stored in the mysql database but before going to mysql database the request will go to memcached(Memcached (pronounced variously mem-cash-dee or mem-cashed) is a general-purpose distributed memory-caching system. It is often used to speed up dynamic database-driven websites by caching data and objects in RAM to reduce the number of times an external data source (such as a database or API) must be read.) for the first time the user infi will go from mysql server to tomcat but next time it will come from the cached info in memcached.(just as browser caching we have datbase caching.)

=> we need to understand the flow of the stack. As a devops we are more focussed on implementation rather than functionality.

//AUTOMATION SETUP//
vagrant, vm virtualbox, bash scripts.

//FLOW OF EXECUTION//
clone source code, bring up VMS, validate that they are working and interacting with each other, setting up services
1.MYSQL
2.memcached(database caching)
3.rabbitMQ(message broker or queying agent)
4.tomcat(java web application service)
5.nginx(load balancer)
6.deploy webapp  
verify using web browser

=>vagrant plugin install vagrant-hostmanager, it maps all the ips with hostnames
==>plugins are used for extra feature, the above one ensures that the hostname and ip address are being stored in /etc/hosts
=>mariadb-server is the package name and mariadb is the service name

=>mysql_secure_installation => it is script which will ask a series of questions just  check the mysql services is secure

==> every sql command ends with a semicolon
==> wheneve you are going to set up any service or anything then you must do the update -y command.

==> memcached -p 11211 -U 11111 -u memcache -d, 11211 => TCP(transmission control protocol) and 11111 => UDP(user datagram protocol), we can validate if the memcached is running on the right port or not by using ss -tunlp | grep 11211
==>network check --> ping app01 -c 4(number of ping packets that will be transmitted)

==>we always start setting up from the backend like database, then queying/caching, application service then web service.

=>Tomcat is an application server to host Java Web Application like vprofile.

Nginx is a frontent server, web server and can be used as a Load balancer.

Mysql is a SQL Database server, similar are Mariadb, MSSql etc
-->grant all privileges on accounts.* TO 'admin'@'%' identified by 'admin123';
==>Above % means admin user of this database can connect to this database from remote machine.
-->sed -i 's/127.0.0.1/0.0.0.0/g' /etc/sysconfig/memcached --> some services only work in local machine, to connect with that service remotely from any other machine we need to do this config change.
0.0.0.0 --> means listen from all the ipv4 addresses
RabbitMQ is the most widely deployed open source message broker.

Memcached is an in-memory key-value store for small chunks of arbitrary data (strings, objects) from results of database calls.

==>application.properties is used by tomcat server to find information of all the backend services
mysql, memcache, RabbitMQ, Elasticsearch

In source code its located in vprofile-project/src/main/resources/application.properties.

==> jre --> java runtime environment --> it is to run java based application
==> jdk --> java devlopment kit --> used to devlop java based applications.

-->Whenever you make any change in the file /etc/systend/system --> execute this command --> systemctl daemon-reload

###COMPUTER NETWORKING###
=>components, OSI model, Classification, Devices, Home Network, IP addresses, Protocols, DNS & DHCP, Network commands.

==>What is COMPUTER NETWORKING?
the communication between two or more network interfaces.

==>COMPONENTS OF CN:-
Two or more computers/devices, cables as links between the computers, network interfacing card(NIC) on each device, computer, 
switches- to connect multiple network interfaces together, router - to connect multiple network together, software called operating system(OS)

==>OSI MODEL:-(OpenSystems Interconnection)
1.people aroungd the world uses computer network to communicate with each other.
2.for the worldwide data communication, systems must be developed whch are compatible to communicate with each other.
3.there should be standard communcation methods and devices.
4.ISO(international organisation of standardiztion) has developed this standard.

communication system is devloped as if it is some kind of language which is to be understood by everyone.

=>This communication model is called as Open System Interconnection(OSI)
=>OSI-ISO model is a seven layer archietecture devloped in 1984.
 
=>The basic elements of a layered model are:-
1.services
2.protocols
3.and interfaces.
#A service is a set of actions that a layer offers to another (higher) layer
#A protocol is a set of rules that a layer uses to exchange information.
#Interface means communication between the layers.

#OSI MODEL:-
physical - bits
data link - frames
network - packets
transport - segmemts
session - data
presentation - data
application - data  

In tcp/ip protocol the application, presentation and session layer are considered to be a single layer.
 
###CLASSIFICATION OF NETWORKS BASED ON GEOGRAPHY###
=>LAN - local area network. ex -room computers
=>WAN - wide area network. ex -internet
=>MAN - metropolitan area network
=>CAN - campus area network
=>PAN - personal area network
###SWITCHES AND ROUTERS###
switches facilitates the sharing of resources by connecting together all the devices, including computers, printers, and servers, in a small business network.switch connects multiple computers together.
  
##ROUTERS
a router connects multiple networks together. A router recieves and sends data on computer networks. Routers are sometimes confused with network hubs, modems, or network switches. However, routers can combine multiple networks together. It connects LAN with WAN.
###HOME NETWORK###
 
###CORPORATE NETWORK DIAGRAM###
 
###IPv4 ADDRESS###
 
32 BIT binary number, range of IPv4 0.0.0.0 to 255.255.255.255
00000000.00000000.00000000.00000000 => lowest possible IPv4 address
11111111.11111111.11111111.11111111 => highest possible IPv4 address
==> Public IP => with the ISP or cloud service provider, ex- 54.86.23.90, this is our identity in network, it is mostly dynamic. 
==>Private IP is for people like us to create our own network.ex - 192.168.1.10, it is mostly static.Its ranges are as follows:-(IMPORTANT)
class A:- 10.0.0.0 -> 10.255.255.255
class B:- 172.16.0.0 -> 172.31.255.255
class C:- 192.168.0.0 -> 192.168.255.255
###PROTOCOLS###
In the networking and communications area, a protocol is the formal specification that defines the procedures that must be followed while transmitting and recieving data. Protocols define the format, timing, sequence and error checking use on the network.
  
we need to know the port numbers as they will be helpful while setting the firewalls, or security grooups. Like computer have an IP address a service running inside the computer will have a port number
###LOOKING OSI 7 LAYER MODEL WITH TCP/IP PROTOCOLS###
 
lets us say tomcat on one machine wants to communicate with mysql on ther machine then
tomcat     ==>              Source 192.168.1.2:8080 Dest 192.168.1.2:3306   ==>                  MySQL                     
192.168.1.2:8080                                                                                                      192.168.1.3:3306     

###NETWORKS COMMANDS###
==>when we get inside the the  multivm file using the vagrant up, and then do ifconfig then it shows the connected ip addresses,
1. connected to nat network
2.connected to IP(the static IP which we provided) address.
3.lastly it shows the loopback address, this is used when computer refers to itself, you can say that it is a local network interface.
==> ping releases the network connectivity from the machine to the IP address on which ping is applied, it shows network connectivity is there or not and the packets are not lost.
==> if i don't want to use a IP address instead i want a name then i will need a DNS server or i can make an entry to the /etc/hosts in root directory. If i want to add the db01 there then i need to write 192.168.40.12 db01
==>if you want to trace the complete path that the computer has taken to reach the target machine then you can use trace root(tracert www.google.in(for example)) . This command is used to see whether there is latency between a computer to some target machine. Then we can see that the latency is where and findout the problem.
==>netstat -antp => tells about all the open TCP ports. if we are root user then only we will be able to see the PID(process ID) 
==> ps -ef | grep apache2 => to search for apache 2 from the processes
==> ss -tunlp => to see open ports on the machine with name and PID
==> nmap => scannig the port of a target, for whether they are open or not. if we are trying to connect two machines, and they are not connecting then we will use nmap to scan the ports to see whether it is open or not.
==>dig www.google.com( for example) => it will show us the DNS lookup, like it will show us that name can be resolved to IP address or any other record. nslookup www.google.com (for example) is also same as the dig command but it is old.
==>route -n => this command is going to show you the gateways
==> arp => used to add or view content of kernels arp table
==>mtr => same as traceroute but it is live (dynamic)
==> we can use telnet command also to see whether a particular port is open or not in the target machine.ex- telnet 192.168.40.12 3306 i.e trying to connect web01 and db01 on port 3306.
###CONTAINERS###
DOCKER-Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure so you can deliver software quickly. With Docker, you can manage your infrastructure in the same ways you manage your applications.
DCKER HOST- computer on which all the things are going to happen.
DOCKER DAEMON- it is the docker service that we are going to install, so we'll have a VM and we'll install the docker engine on that and run the containers., we'll run them from image and the image we'll be get from registry.
 
client can be on the same machine or different machine or different machine, we'll create a VM , we'll install the docker engine and that will have the docker client also and with
docker build - we can build our own images
docker pull - to pull the images from registry.
docker run - run the container from the image.
docker containers are created from docker images.
==> docker run hello-world => this will test whether the docker installation is fine or not.
==>docker images => available images on your system., docker ps => will show running containers , docker ps -a => will show you all the containers.
==>docker run --name web01 -d -p 9080:80 nginx --> -d ==> to run the processes in background. -p to assign hostport to container port.
==>Container will be running in internal network, so it can't be accessed from outside, in order to access it from outside we use port mapping.
==>To access the container locally we need its ip, so use docker inspect containerName/ContainerID. Now type curl http://IPaddress:containerPort. for example(curl http://172.17.0.2:80)
==>If we want to run multiple containers together then there is concept of docker compose, it will read file dockercompose.yaml file.
==> docker compose down to stop and remove the container, docker system prune -a --> will remove all the containers and images if they are not used.

BASH SCRIPTING:-
In Linux, process automation relies heavily on shell scripting. This involves creating a file containing a series of commands that can be executed together.
==>Bash script is a text file that may ave an extension .sh , it will start with a shebang character #! --> it tells the path of the interpreter i.e open the interpreter and execute the commands written in it.
==>to run a bash script, do ./scriptName , to comment inside bashscript use #comment. we need to change the permissions of the bash script file if it doesnot execute --> chmod +x bashfileName.
#Variable Declaration
PACKAGE="httpd wget unzip"
SVC="httpd"
URL="https://www.tooplate.com/zip-templates/2098_health.zip"
ART_NAME="2098_health"
TEMPDIR="/tmp/webfiles"
==>to use variable, $variableName.

command line argument:-
==>value of variable 0 is by default the name of the script. i.e. echo $0 prints the name of the bashscript file.
==>If we try to echo a variable that is not defined then it will be shown empty.
==>$1-$9, the first 9 arguments to the bash script.
==>wget $1 > /dev/null  -->we are asking for the URL
unzip $2.zip > /dev/null --> then we are asking for the artifact name
sudo cp -r $2/* /var/www/html/
i.e after writing this command in the bashscript, our code becomes reusable.

==> echo $? --> prints the exit code --> if it is 0 the previous command was a success, it is non-zero then the previous commmand failed.
==> echo $RANDOM --> give random number in the range 0 â€“ 32767

QUOTES --> single and double both, inside double quotes the meaning of special character is there but inside single quote the meaning of special character is not there.
[root@scriptbox ~]# echo 'I have $SKILL skills'
I have $SKILL skills --> for single quotes

[root@scriptbox ~]# echo "I have $SKILL skills"
I have Devops skills --> for double quotes

[root@scriptbox ~]# echo "due to $VIRUS we lost $9 million"
due to covid19 we lost  million
[root@scriptbox ~]# echo "due to $VIRUS we lost \$9 million"
due to covid19 we lost $9 million --> after using backslash in front of any special character, it special meaning is ignored.

==>COMMAND SUBSTITUTION --> it stores the output of the command in a variable.
[root@scriptbox ~]# UP=`uptime` --> to store the command o/p use `` --> backticks
[root@scriptbox ~]# echo $UP

[root@scriptbox ~]# CURRENT_USER=$(who) --> one more way
[root@scriptbox ~]# echo $CURRENT_USER
vagrant pts/0 2023-12-28 07:11 (10.0.2.2)

so --> either `` OR $(command)

EXAMPLE:-
[root@scriptbox ~]# FREE_RAM=`free -m | grep Mem | awk '{print $4}'`
[root@scriptbox ~]# echo "free RAM is $FREE_RAM mb."
free RAM is 767 mb.

EXPORTING VARIABLES --> if you want to make variables permanent for a user or for every user in the system, then we have to export the variable.
The variable exists in the parent shell, but not in the child shell, so we can export variableName, so the varible is available for all the child shell from this parent shell.
==> Exporting the variable makes the variable global for all the child shells. 
--> BUTT if i logout from the current shell, and login again the variable is lost.

==> In every user's home directory there is a hidden file .bashrc, if we place our export and variable name in this file, then it will become permanent for the root user.
-->when any user login the bashrc file is sourced --> source .bashrc --> i.e in order to make changes visible logout and login again.
-->if we want to make the variable permanent for every user then update the /etc/profile 

-->MORAL --> if you want to make variable permanent for a user the update the .bashrc file
         --> if you want to make variable permanent for everyone then update the /etc/profile.

USER INPUT ==> read -p 'Username: ' USR --> -p is for prompt
               read -sp 'Password: ' pass --> -sp is for suppressing the input

we don't want script to be interactive in devops since it is error prone.
--> whenever a process is running a pid file must be created. cat /var/run/httpd/httpd.pid, if we will stop the service the file will cease to exist.

CRON JOBS --> if we want to run a process again and again a particular schedule then we use cron jobs, they are scheduled tasks
crontab -e is going to edit --> i.e it will open a vim editor ==>
# minute hours dayOfMonth month dayOfWeek COMMAND
# 30 20 * * 1-5 COMMAND
* * * * * /opt/scripts/11_monit.sh &>> /var/log/monit_httpd.log
* --> for every interval
==> we have created an intelligent script that will be running on a fixed schedule.


REMOTE COMMAND EXECUTION --> how can we execute command from scriptbox to web01 and web02 and web03.
-->we are going to add names to IP mapping in the scriptbox. so scriptbox can refe to all the machines with their names and not IP addresses.

-->Add the ip addresses to the /etc/hosts --> 192.168.10.13 web01
                                              192.168.10.14 web02
                                              192.168.10.15 web03

==>ssh vagrabt@web01 trying to SSH into a virtual machine named "web01" using the Vagrant user
==>whenever i was trying to log into web01, web02, it was asking me password, but for web03 --> Permission denied (publickey) --> so ubuntu doesnot allow password login.
-->vagrant ssh web03 is keybased login --> if any linux machine you are trying to login with password and if it throws you that public access denies then, open the /etc/ssh/sshd_config --> and find the line password authentication, if it is no then do it yes.
-->then restart the ssh service --> in ubuntu the name of ssh service is ssh only.
-->add user devops in all the VMs --> web01 web02 web03
-->now from scriptbox we can remote execute commands in these VMs --> ssh devops@web01 uptime --> shows uptime of web01 and then come back to same command ineterface.

SSH key Exchange --> we can do the above but the problem is everytime it asks for password.
BUT there is one more way to login i.e key based. key based login are considered more safer
--> To generate the key --> ssh-keygen
[root@scriptbox ~]# ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /root/.ssh/id_rsa. --> this works as a key
Your public key has been saved in /root/.ssh/id_rsa.pub. --> this works as a lock
so we will put the lock(public key) in web01 web02 web03 by --> ssh-copy-id user@hostname 
==>CONCLUSION --> now if we will do --> ssh user@hostname command --> it will not ask for password

-->/root/.ssh/id_rsa --> private key will be here --> it is longer than the public key.
-->/root/.ssh/id_rsa.pub --> public key will be here.
-->when lock matches with the key(since both are generated in pairs) then we get authenticated.
--> now when we will do ssh user@hostname then it is actually written --> ssh -i /root/.ssh/id_rsa user@hostname

==>to push file from one VM to other VM do --> scp sourceFile destination:<file path> --> scp testfile.txt devops@web01:/tmp/
-->scp doesnot asks any password, if there is any password then the key is not exchanged.
--> ############################################################for deployment of multiple VMs.
#!/bin/bash

USR='devops'

for host in $(cat remhosts)
do
  echo
  echo "############################################"
  echo "connecting to $host"
  echo "pushing script to $host"
  scp multios_websetup.sh $USR@$host:/tmp/
  echo "executing script on $host"
  ssh $USR@$host sudo /tmp/multios_websetup.sh
  ssh $USR@$host sudo rm -rf /tmp/multios_websetup.sh
  echo "############################################"
  echo
done
~
##################################################################

AWS ==> Cloud Computing --> Cloud computing is the on-demand delivery of IT resources over the Internet with pay-as-you-go pricing. Instead of buying, owning,
and maintaining physical data centers and servers, you can access technology services, such as computing power, storage, and databases, on an as-needed basis 
from a cloud provider like Amazon Web Services (AWS).

IAAS -- infrastructure as a service
PAAS -- platform as a service
SAAS -- software as a service

We will keep US based region, as it is less expensive.

EC2--> Elastic Compute Cloud-->About VMs and related services.
(refer to the slides for more)

AMI --> amazon machine image.

instance type --> ex - M4, C4, F1, I3 --> size of the instance i.e how much CPU, RAM the instance provide
refer to this for more info --> https://aws.amazon.com/ec2/instance-types/

EBS --> Elastic block storage. --> amazon provides su with flexible, cost effective, and easy to use data storage options for your instances.
EBS --> is a virtual hard disk on which you can store data as well as OS.

Tag -->Tags are key and value pairs that act as metadata for organizing your AWS resources. With most AWS resources, you have the option of adding tags when you create the resource.
Examples of resources include an Amazon Elastic Compute Cloud (Amazon EC2) instance, an Amazon Simple Storage Service (Amazon S3) bucket, or a secret in AWS Secrets Manager.

Security group --> A security group controls the traffic that is allowed to reach and leave the resources that it is associated with. For example, after you associate a security group with an EC2 instance,
it controls the inbound and outbound traffic for the instance.

Amazon EC2 uses public key cyrptography to encrypt and decrypt login information.

ONE AWS region will have minimum two zones.

==>Every EC2 instance have a by default firewall --> security group.

==>check for users before login --> for AMI ec2-user is the user generally, can be ubuntu or centos 

==>Inbound & Outbound Rules:-
inbound --> traffic coming from outside on the instance.
outbound --> traffic going from instance to outside

==>After we create a key pair, the private key will bedownloaded in my computer and public key will be inserted in the instance. 

==>firewalls are gatekeepers for traffic coming from outside.
->divide your key based on the environments i.e for devlpoers one key, production one key, and other key for other departments.
->our loclahost allows opens port 80 for us to access from outside but, our SG allows only on port 22, so we will modify the inbound rules for port 80.
->when we stop and start our ec2 instance the public IP address will change, but the private IP will remain same.
->if we want static public IP then we should use elastic IP. we get 5, if we want more, we can contact the AWS support team and purchase them.
->the allocated elastic IP is only for us in the whole world. We are going to associate this elastic IP with our instance.
->security group, public IP is all for Network Interface, all the firewall rules that we are giving is for this network interface.
->we can add more network interfaces and attach it to our instance as well.
->while we create our own custom AMI, then some problem could be there, that could be seen from the system log(though it is not live).
->for changing the instance type, first stop the running instance.
->we should also remove the elastic IP, as if we will keep it, we will be charged for it.
->we need to configure our AWS CLI i.e authentication for our AWS account.
->we will use this AWS CLI to manage our entire AWS account and for that we will give it adminstrator access.
->if we are creating this user for somebody else who need access to a specific service like s3 access then we need to give s3 policy only. We don't need to give adminstrator access to everybody.
->never share your access keys and secret access keys, because they have the adminstrator access and never post it in public repositories as there are bots scanning for these keys all over internet.

==>configuring AWS CLI
aws configure --> provide the info
->all the info will be stored in `/.aws/
->$ ls ~/.aws/ --> config  credentials
->config file will have region and output format, credentials will have keys
->aws sts get-caller-identity --> user id, account, ARN(amazon resource names{uniquely identify AWS resources})
->$ aws ec2 describe-instances --> gives data in JSON format
->we can use chatgpt for generating cli commands.

==>EBS(elastic block storage) --> virtual harddisk for our EC2 instance.
->it will provide two things --> EBS volume & Snapshot(which will be the backup of EBS volume)
->for more info refer to EBS types 
->we should name our volumes using proper naming as it becomes easy for us to identify if we have multiple volumes.
->instance and volume needs to be in the same zone, then only volume can be connected to the instance
->fdisk -l --> going to list all your partitions.
->create disk partion in xvdf hardisk --> fdisk /dev/xvdf

###########################################################################
->Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.

Device does not contain a recognized partition table.
Created a new DOS disklabel with disk identifier 0xd116dc2e.

Command (m for help): m

Help:

  DOS (MBR)
   a   toggle a bootable flag
   b   edit nested BSD disklabel
   c   toggle the dos compatibility flag

  Generic
   d   delete a partition
   F   list free unpartitioned space
   l   list known partition types
   n   add a new partition
   p   print the partition table
   t   change a partition type
   v   verify the partition table
   i   print information about a partition

  Misc
   m   print this menu
   u   change display/entry units
   x   extra functionality (experts only)

  Script
   I   load disk layout from sfdisk script file
   O   dump disk layout to sfdisk script file

  Save & Exit
   w   write table to disk and exit
   q   quit without saving changes

  Create a new label
   g   create a new empty GPT partition table
   G   create a new empty SGI (IRIX) partition table
   o   create a new empty DOS partition table
   s   create a new empty Sun partition table


Command (m for help): n
Partition type
   p   primary (0 primary, 0 extended, 4 free)
   e   extended (container for logical partitions)
Select (default p): p
Partition number (1-4, default 1): 1
First sector (2048-10485759, default 2048):
Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-10485759, default 10485759):

Created a new partition 1 of type 'Linux' and of size 5 GiB.

Command (m for help): p
Disk /dev/xvdf: 5 GiB, 5368709120 bytes, 10485760 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: dos
Disk identifier: 0xd116dc2e

Device     Boot Start      End  Sectors Size Id Type
/dev/xvdf1       2048 10485759 10483712   5G 83 Linux

Command (m for help): w
The partition table has been altered.
Calling ioctl() to re-read partition table.
Syncing disks.

[root@ip-172-31-94-111 ~]# fdisk -l
Disk /dev/xvda: 10 GiB, 10737418240 bytes, 20971520 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: gpt
Disk identifier: BC4822EF-1C6F-44BE-A322-E1AFC3BF04A6

Device     Start      End  Sectors Size Type
/dev/xvda1  2048     4095     2048   1M BIOS boot
/dev/xvda2  4096 20971486 20967391  10G Linux filesystem


Disk /dev/xvdf: 5 GiB, 5368709120 bytes, 10485760 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: dos
Disk identifier: 0xd116dc2e

Device     Boot Start      End  Sectors Size Id Type
/dev/xvdf1       2048 10485759 10483712   5G 83 Linux
#####################################################################

--> formating the disk partition
linux provides multiple utitlity for partitioning -> mkfs(then hit tab 2 times)
mkfs.ext4 /dev/xvdf1 --> we formatted the disk partition that we just created

-->mounting the disk partition
i want to mount xvdf1 partition on images
->mount /dev/xvdf1 /var/www/html/images/ --> this is temporary mount if i will reboot my machine it will unmont.
-->unmounting the disk partition
umount <directory_path>

>>>VVIMP --> for mounting the disk partition permanently we need to edit the /etc/fstab file
partition_path  where you want to mount it  format type  options      dumping_code file_system_check
/dev/xvdf1      /var/www/html/images         ext4         defaults        0          0
-->Now --> mount -a --> (it will mount all the partitions in /etc/fstab file)

--> umount /var/www/html/images --> if this throws an error --> run lsof <directory that is mouted inside that directory> --> then umount it.
-->IMP -> to remove the volume --> first detach --> then delete it --> otherwise you will pay for it.
if you reare not able to connect to the EC2 instance then connect the internet from your mobile data and try connecting by it

-->for database-
->follow same steps for creating formating and mounting.
->mkdir -p /var/lib/mysql --> mount xvdf1 to this path
->so even before you install the service, the partition, formatted, mounted perfectly
->what will happen if we by chance delete the data --> we will take Snapshot. --> before loosing the dat we will tak snapshot.
->after deleting the data --> stop the service to prevent any overwrite in the mysql file.
->cd to home directory of root user ->> umount /var/lib/mysql/ ->> detach the disk volume from aws console ->> create volume from the snapshot taken
->> attach the created volume with the instance. ->> then do mount -a in git bash
->snapshot is not just for storing the data, it can be used to change zones, size of volume, type of volume, encrypting the data. 
->>if it snapshot of root volume then we create image from that.
->>manage fast snapshot restore --> for larger volumes ->> extra charges will be applied.
->>we can copy snapshot to other region.
->>modify --> we can make snapshot public, or share it other aws account.

ELASTIC LOAD BALANCING:-
Elastic Load Balancing (ELB) automatically distributes incoming application traffic across multiple targets and virtual appliances in one or more Availability Zones (AZs).
-->you have multiple servers, and for accesing them there is one end end point, it s load balancer
-->application load balancer ->> layer 7 load balancer. ->> only used for http & https.
-->network load balancer ->>  layer 4 of the OSI. ->> can haldle millions of request per second. ->> we can create a elastic IP and attach it to the load balancer ->> so it is stattic IP.
->>create an ami from this instance ->> we will create a image that will have website in it. So we can launch instance from that, so we cluster of AMIs having the same data.
->>from snapshot you can create a volume but from ami we can create a instance.
->>we can change AMI region, modify its specification 
->we can create AMI automatically using EC2 image builder else manually as we do.
->we can launch the instance using AMI --> but we need to go through the manual process ->> use template to launch fast



GIT:-
What is a version control system?
Version control, also known as source control, is the practice of tracking and managing changes to software code.

==>localised VCS, centralised VCS, distributed VCS

==>git remote add origin URL
$ cat .git/config
[core]
        repositoryformatversion = 0
        filemode = false
        bare = false
        logallrefupdates = true
        symlinks = false
        ignorecase = true
[remote "origin"]
        url = https://github.com/Amit-unchartered/Amit-Agrawal-git.git
        fetch = +refs/heads/*:refs/remotes/origin/*


==>git keeps track of files not directories

==>git log --oneline --> for getting short id
==>git show id -> it will show the same thing that we will see on the command line.

==>To create a new branch --> git branch -c <branch_name>
==>git branch -a --> will show all the branches

==>ROLLING BACK IN GIT:-
1. if you have modified a file and not gone into the stash area, git checkout <file_name> --> it will rollback to original
2. git diff --> it will show difference in the file that you have changed --> if you are ok with it --> git add .
-->If we want to rollback from staging area then --> git restore --staged <file_name>.
-->If we want to see the differences in the file after entering the staging area then --> git diff --cached
3. If we have committed the message and want to rollback --> git revert HEAD --> a new commit named revert <"file_name"> --> will be formed
4. if we don't want to have history whatsoever --> git reset --hard id(above this id everything will be removed).
5.$ cat .git/config
[core]
        repositoryformatversion = 0
        filemode = false
        bare = false
        logallrefupdates = true
        symlinks = false
        ignorecase = true
[remote "origin"]
        url = https://github.com/Amit-unchartered/titanwork.git --> the authentication will be based upon username and password, so there are chances of exposing it.        fetch = +refs/heads/*:refs/remotes/origin/*
[branch "main"]
        remote = origin
        merge = refs/heads/main

==> to overcome this github provides SSH based login, ans almost every remote github repository provides SSH based authentication --> which will be through SSH keys.
==>first --> rm -rf .ssh/* --> to remove anything that is alreasy present in .ssh folder, then --> ssh-keygen.exe --> to generate a SSH key.
-->enter the public ssh key in the github after adding SSH key.
-->git clone SSH_link_from_github

MAVEN --> BUILD TOOL --> Maven is a build automation tool used primarily for Java projects. Maven can also be used to build and manage projects written in C#, Ruby, Scala, and other languages. 
-->source code --> compile --> tests --> packaging --> health checks.
write scripts in XML format